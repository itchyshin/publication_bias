---
title: Methods for testing publication bias in ecological and evolutionary meta-analyses
author: Shinichi Nakagawa, Malgorzata Lagisz, Michael D. Jennions, Julia Koricheva, Daniel W.A. Noble, Timothy H. Parker, Alfredo Sanchez-Tojar, Yefeng Yang, Rose O'Dea
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    code_download: yes
    code_folding: hide
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
subtitle: Supplementary Information Appendix S2 - Publication bias tests for ecology & evolution
---

```{r,echo=FALSE, cache=FALSE}
## numbers >= 10^5 will be denoted in scientific notation, and rounded to 2 digits
options(digits=3)
```

```{r setup, echo = FALSE, eval = TRUE}
###################################################################
# Worked example publication bias methodology
#
# Code written by:
#
#         Alfredo Sanchez-Tojar (alfredo.tojar@gmail.com); Departament of Evolutionary Biology, Bielefeld University, Germany
#
#         Yefeng...
#
# Code validated by:
#
#         Shinichi Nakagawa (); ...
#
# Script first created on November 20th, 2020

###################################################################
# Description of script and Instructions
###################################################################

# This script is to generate worked examples to show how to test for
# publication bias when several layers of non-independence exist in
# the data, which is common for meta-analytic datasets in ecology 
# and evolution. We provide two worked examples, one for correlation
# effect sizes (r) and one for mean comparisons (SMD and lnRR).

rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE)
pacman::p_load(dplyr,metafor,gt,pander,stringr,openxlsx,rotl,ape)

# necessary custom functions

# loading function writen by D.W.A.Noble to calculate I2 (more in https://github.com/daniel1noble/metaAidR/blob/master/R/I2.R)
source("I2_DWANoble.R")

# Function to obtain marginal R^2 (written by Shinichi Nakagawa)
R2 <- function(model){
  warning("Make sure you have the observation (effec size) level random effect as the last in the formula\n")
  
  # fixed effect variance
  fix <- var(as.numeric(as.vector(model$b) %*% t(as.matrix(model$X))))
  
  # marginal
  R2m <- fix / (fix + sum(model$sigma2))
  R2
  
  # conditional
  R2c <- (fix + sum(model$sigma2) - model$sigma2[length(model$sigma2)]) / 
    (fix + sum(model$sigma2))
  
  R2s <- c(R2_marginal = R2m, R2_coditional = R2c)
  
  return(R2s)
}

# extracting mean and CI from each metafor model
estimates.CI <- function(model){
  db.mf <- data.frame(model$b,row.names = 1:nrow(model$b))
  db.mf <- cbind(db.mf,model$ci.lb,model$ci.ub,row.names(model$b))
  names(db.mf) <- c("mean","lower","upper","estimate")
  return(db.mf[,c("estimate","mean","lower","upper")])
}


# function to convert r to Zr
r.to.Zr<-function(r){
  Zr<-round(0.5*(log(1+r)-log(1-r)),3)
}


# function to obtain variance
VZr <- function(N){
  VZr<-1/(N-3)
}
```

## 1 - Correlation effect sizes

```{r, results="hide"}
# importing dataset with correlation coefficients
# dataset.r.original <- read.csv("../data/Sanchez-Tojar_et_al_2018_eLife_Meta4.csv", stringsAsFactors = FALSE)
dataset.r.original <- read.xlsx("ft044.xlsx", colNames = TRUE, sheet = 1)

# transforming r to Zr for the analyses, and estimating VZr for the weighting
dataset.r.original$Sample.size <- as.numeric(dataset.r.original$Sample.size)

# subset dataset to those with 4 or more individuals (this removes two rows, one without sample size and one with sample size = 3)
dataset.r.original <- dataset.r.original[dataset.r.original$Sample.size>3 & !(is.na(dataset.r.original$Sample.size)),]

dataset.r.original$yi <- r.to.Zr(dataset.r.original$Correlation)
dataset.r.original$vi <- VZr(as.numeric(dataset.r.original$Sample.size)) #the effect based on 3 individuals won't be able to be analyzed because VZr is then infinite (see VZr function above to understand). Also, there is a missing sample size. 

# renaming some variables to make it easier
dataset.r.original$study <- dataset.r.original$Reference
dataset.r.original <- dataset.r.original[ , !names(dataset.r.original) %in% c("Reference")]
```

For our first worked example, we used the dataset provided by Garamszegi et al. (2012), who tested the hypothesis that behaviours are correlated across studies and species (behavioural syndrome), which they found support for. Here, we reanalysed the data from Garamszegi et al. (2012) by first conducting a phylogenetic multilevel intercept-only meta-analytic model and then testing for evidence of publication bias following the approaches outlined by Nakagawa et al. (main manuscript).

### 1.1 - Phylogenetic relationships

Since multiple species (n = `r length(unique(dataset.r.original$Species))` species) are included in this dataset, we need to account for phylogenetic nonindependence in our statistical models. For that, we build a phylogenetic tree for all these species (Figure S1) by retrieving their phylogenetic relationships from the Open Tree of Life (Hinchliff et al. 2015) using the R package `rotl` (Michonneau, Brown, and Winter 2016). We estimated branch lengths following Grafen (1989) as implemented in the function 'compute.brlen()' of the R package `ape` (Paradis and Schliep 2019). We then constructed a phylogenetic relatedness correlation matrix that will be fitted as part of the random effect structure of our models (see below).

```{r fig.height = 9, fig.width = 9.5, fig.align = "center"}
# First, we searched for the species names in the Open Tree Taxonomy (Rees and Cranston 2017) to confirm that all species names were correct, and that no synonyms or typos were present in the database.

# fixing a typo in the original list of species names
dataset.r.original$Species <- ifelse(dataset.r.original$Species=="Acrochephalus schoenobaenus",
                                     "Acrocephalus schoenobaenus",
                                     dataset.r.original$Species)

# updating a name that was not being well recognized by the Open Tree Taxonomy
dataset.r.original$Species <- ifelse(dataset.r.original$Species=="Eurotestudo boettgeri",
                                     "Testudo boettgeri",
                                     dataset.r.original$Species)

# fixing another typo in the original list of species names
dataset.r.original$Species <- ifelse(dataset.r.original$Species=="Taenopygia guttata",
                                     "Taeniopygia guttata",
                                     dataset.r.original$Species)

# # obtaining dataframe listing the Open Tree identifiers potentially matching our list of species (be aware that this will take a few minutes, and you can load the data below)
taxa <- tnrs_match_names(names = unique(dataset.r.original$Species))

# saving the taxonomic data created on the 18th of February 2021 to speed the process in the future and make the code fully reproducible if taxonomic changes are implemented in the future
save(taxa,file = "taxa_Open_Tree_of_Life_20210218.RData")

# # loading the taxonomic data (taxa) created on the 18th of February 2021
# load("taxa_Open_Tree_of_Life_20210218.RData")

# # check approximate matches
# taxa[taxa$approximate_match==TRUE,]
# 
# # check synonyms matches
# taxa[taxa$is_synonym==TRUE,]
# 
# # check number of matches
# taxa[taxa$number_matches>1,]

# some further checks
ott_id_tocheck <- taxa[taxa$number_matches != 1,"ott_id"]

# for(i in 1:length(ott_id_tocheck)){
#   print(inspect(taxa, ott_id = ott_id_tocheck[i]))
# }

#all phylogenetic data seems in order now

# however, the ott_id for Parma unifasciata cannot be found when retrieving the phylogenetic relationships, so to trick this we are going to use the ott_id of another Parma species, Parma oligolepis (ott_id = 323186), which is this case it is fine because we only include two species belonging to the genus Parma, and therefore, the phylogenetic relationship will be the same for our purposes
# tnrs_match_names(names = 'Parma oligolepis')
taxa[taxa$unique_name=="Parma unifasciata","ott_id"] <- 323186

# retrieving phylogenetic relationships among taxa in the form of a trimmed sub-tree
tree <- tol_induced_subtree(ott_ids = taxa[["ott_id"]], label_format = "name")

# # we need to check for the existence of polytomies
# is.binary.tree(tree) # No polytomies, so we can proceed.

# to confirm that our tree covers all the species we wanted it to include, and make sure that the species names in our database match those in the tree, we use the following code

tree$tip.label <- gsub("_"," ", tree$tip.label)
# intersect(as.character(tree$tip.label), as.character(dataset.r.original$Species))
# setdiff(as.character(dataset.r.original$Species), as.character(tree$tip.label)) #listed in our database but not in the tree
# setdiff(as.character(tree$tip.label),as.character(dataset.r.original$Species)) # listed in the tree but not in our database

# All but Pan and Parma oligolepis are the same species, the "problem" is that synonyms have been used in the tree. We are going to leave all the names as in Open Tree of Life except Pan and Parma oligolepis, which we are going to substitute by Pan troglodytes and Parma unifasciata

# we start by fixing the following names in the tree
tree$tip.label[tree$tip.label=="Pan"]<-"Pan troglodytes"
tree$tip.label[tree$tip.label=="Parma oligolepis"]<-"Parma unifasciata"

# setdiff(as.character(dataset.r.original$Species), as.character(tree$tip.label)) #listed in our database but not in the tree
# setdiff(as.character(tree$tip.label),as.character(dataset.r.original$Species)) # listed in the tree but not in our database


# changing the names in our database to follow those in the tree. We are creating a new Species.updated variable so that it is clear that this list of Species is an updated version compared to the original one
dataset.r.original$Species.updated <- dataset.r.original$Species

dataset.r.original$Species.updated <- ifelse(dataset.r.original$Species.updated=="Carduelis chloris",
                                             "Chloris chloris",
                                             dataset.r.original$Species.updated)

dataset.r.original$Species.updated <- ifelse(dataset.r.original$Species.updated=="Dendroica pensylvaniaca",
                                             "Setophaga pensylvanica",
                                             dataset.r.original$Species.updated)

dataset.r.original$Species.updated <- ifelse(dataset.r.original$Species.updated=="Sylvia melanocephala",
                                             "Curruca melanocephala",
                                             dataset.r.original$Species.updated)

# setdiff(as.character(dataset.r.original$Species.updated), as.character(tree$tip.label)) #listed in our database but not in the tree
# setdiff(as.character(tree$tip.label),as.character(dataset.r.original$Species.updated)) # listed in the tree but not in our database

# all in order

# we can now save the tree
save(tree, file = "tree_20211802.Rdata")

# # we can now load the saved tree (tree)
# load("tree_20211802.Rdata") 

# compute branch lengths of tree
phylo_branch <- compute.brlen(tree, method = "Grafen", power = 1)

# # check tree is ultrametric
# is.ultrametric(phylo_branch) # TRUE

# matrix to be included in the models
phylo_cor <- vcv(phylo_branch, cor = T)

# finally, save matrix for future analyses
save(phylo_cor, file = "phylo_cor.Rdata")

# # we can now load the saved matrix (phylo_cor)
# load("phylo_cor.Rdata") #phylo_cor


# Last but not least, let's plot the tree to ease visualization of the species and their phylogenetic relationships

# we can then plot the tree
plot(tree, type = "fan", cex=0.65, label.offset =.05, no.margin = TRUE) #check: https://www.rdocumentation.org/packages/ape/versions/5.3/topics/plot.phylo

```

**Figure S1.** Phylogenetic tree of all species included in this dataset. Notice that some of the names shown in the tree correspond to the most updated synonyms according to the Open Tree Taxonomy (Rees and Cranston 2017) of those originally avialable in the dataset provided by Garamszegi et al. (2012).

<br/><br/>

### 1.2 - Meta-analytic model

Then, we used the data from Garamszegi et al. (2012) to provide a worked example on how to test of publication biases in datasets with several layers of non-independence and high heterogeneity (more in the main text), which is common for meta-analyses in ecology and evolution (e.g. Senior et al. 2016; Noble et al. 2017). Detailed results of the meta-analysis are shown in Table S1.

```{r}
# From the article:

# creating a unit-level random effect to model residual variance in metafor
dataset.r.original$obsID <- 1:nrow(dataset.r.original)

# running multilevel intercept-only meta-analytic model
meta.analysis.model.1 <- rma.mv(yi, vi,
                                mods=~1,
                                random=list(~ 1 | obsID, ~ 1 | study, ~ 1 | Species.updated),
                                R = list(Species.updated = phylo_cor), #phylogenetic relatedness
                                method="REML",data=dataset.r.original)

# extracting the mean, 95% confidence intervals and 95% prediction intervals
#print(meta.analysis.model.1, digits=3)
metaanalytic.mean.model.1 <- predict(meta.analysis.model.1, digits=3)
#forest(meta.analysis.model.1)

# estimating relative heterogeneity I2
#I2.model.1 <- I2(meta.analysis.model.1,method = c("Shinichi"))*100

I2.model.1 <- I2(meta.analysis.model.1, 
                 dataset.r.original$vi, 
                 ME = FALSE, sims = 1500, phylo = "Species.updated", obs = "obsID")

# and absolute heterogeneity Q
Q.model.1 <- c(meta.analysis.model.1$QE)

# creating a table to show the heterogeneity estimates
table.model.1 <- data.frame(n=length(unique(dataset.r.original$study)),
                            k=nrow(dataset.r.original),
                            mean=round(metaanalytic.mean.model.1[[1]],2),
                            CI=paste0("[",round(metaanalytic.mean.model.1[[3]],2),",",round(metaanalytic.mean.model.1[[4]],2),"]"),
                            PI=paste0("[",round(metaanalytic.mean.model.1[[5]],2),",",round(metaanalytic.mean.model.1[[6]],2),"]"),
                            I2_obsID=paste0(round(I2.model.1[1,1]*100,1),"\n[",round(I2.model.1[1,2]*100,1),",",round(I2.model.1[1,3]*100,1),"]"),
                            I2_paperID=paste0(round(I2.model.1[2,1]*100,1),"\n[",round(I2.model.1[2,2]*100,1),",",round(I2.model.1[2,3]*100,1),"]"),
                            I2_phylo=paste0(round(I2.model.1[4,1]*100,1),"\n[",round(I2.model.1[4,2]*100,1),",",round(I2.model.1[4,3]*100,1),"]"),
                            I2_total=paste0(round(I2.model.1[5,1]*100,1),"\n[",round(I2.model.1[5,2]*100,1),",",round(I2.model.1[5,3]*100,1),"]"),
                            Q=round(Q.model.1,1))

rownames(table.model.1) <- NULL

# creating a fancy table using the R package 'gt'
table.model.1.gt <- table.model.1 %>% 
  gt() %>% 
  cols_label(n=md("**n**"),
             k=md("**k**"),
             mean=md("**Meta-analytic mean**"),
             CI=md("**95% CI**"),
             PI=md("**95% PI**"),
             I2_obsID=md("***I*<sup>2</sup><sub>residual</sub>\n(%)**"),
             I2_paperID=md("***I*<sup>2</sup><sub>study</sub>\n(%)**"),
             I2_phylo=md("***I*<sup>2</sup><sub>phylogeny</sub>\n(%)**"),
             I2_total=md("***I*<sup>2</sup><sub>total</sub>    \n(%)**"),
             Q=md("***Q*<sub>test</sub>**")) %>%
  cols_align(align = "center") %>%
  tab_source_note(source_note = md("n = number of studies; k = number of effects; CI = confidence interval; PI = prediction interval; *I*<sup>2</sup> = heterogeneity; *Q*<sub>test</sub> = Cochrane's *Q* test. *I*<sup>2</sup> are shown with their respective 95% CI. *I*<sup>2</sup><sub>phylogeny</sub> is equivalent to phylogenetic heritability or *H*<sup>2</sup>.")) %>%
  tab_options(table.width=770)

table.model.1.gt

```

**Table S1.** Results of the phylogenetic multilevel intercept-only meta-analysis testing the relationship between behaviours across species. Estimates are presented as standardized effect sizes using Fisherâ€™s transformation (i.e. *Zr*).

<br/><br/>

### 1.3 - Publication bias

#### **1.3.1 - The two-step approach**

To test for small-study effects, we are going to follow the two-step approach that we suggested in the main text. First, we run a multilevel meta-regression that has the same random effect structure as the meta-analytic model (Table S1) and that includes the effect sizes' standard errors (SE or sei) as the only moderator (see Equation 21 from the main text). If the slope of this moderator is statistically significant, then we run an additional multilevel meta-regression including the effect sizes' sampling variances (SV or vi) as the only moderator (see Equation 22 from the main text), which allows us to obtain an overall effect (the intercept or B0) after accounting for small-study bias, and this overall is less downwardly  biased when modeling sampling variance than when modeling standard errors (more in the main text; Doucouliagos 2012, 2014).

```{r}
# creating a varible for the standard error of each effect size (i.e. the square root of the sampling variance, see Figure 1 from the main manuscript)
dataset.r.original$sei <- sqrt(dataset.r.original$vi)

# Application of Equation 21 from the main manuscript
publication.bias.model.1.se <- rma.mv(yi, vi,
                                      mods=~1+sei,
                                      random=list(~ 1 | obsID, ~ 1 | study, ~ 1 | Species.updated),
                                      R = list(Species.updated = phylo_cor), #phylogenetic relatedness
                                      method="REML",data=dataset.r.original)

#print(publication.bias.model.1.se,digits=3)

# extracting the mean and 95% confidence intervals
estimates.publication.bias.model.1.se <- estimates.CI(publication.bias.model.1.se)
```

##### **1.3.1.1 - Modelling SE (Eq.21)**

According to the meta-regression, there is evidence of small-study effects since the slope of the moderator (i.e. SE) is marginally statistically significant (**slope = `r round(estimates.publication.bias.model.1.se[2,2],2)`, 95% CI = [`r round(estimates.publication.bias.model.1.se[2,3],2)`,`r round(estimates.publication.bias.model.1.se[2,4],2)`]**; *R<sup>2</sup><sub>marginal</sub>* = `r round(R2(publication.bias.model.1.se)[1]*100,1)`%; Figure S1), showing that effect sizes with larger SE are larger, and thus, showing evidence that some small effect sizes with large SE are seemingly missing. Since this meta-regression shows some evidence of small-study bias, we can the proceed to run the meta-regression suggested in Equation 22 from the main text, so that we can estimate an overall effect size for the meta-analysis after accouting for the existence of small-study bias.

```{r fig.height = 5.5, fig.width = 7.5, fig.align = "center"}
publication.bias.model.1.se.plot <- predict(publication.bias.model.1.se)

newdat <- data.frame(sei=dataset.r.original$sei,
                     fit=publication.bias.model.1.se.plot$pred,
                     upper=publication.bias.model.1.se.plot$ci.ub,
                     lower=publication.bias.model.1.se.plot$ci.lb,
                     stringsAsFactors=FALSE)

#newdat <- unique(newdat[order(newdat$sei),])
newdat <- unique(newdat[order(newdat$sei),])

xaxis <- dataset.r.original$sei
yaxis <- dataset.r.original$yi

plot(xaxis,yaxis,
     type="n",
     ylab="",
     xlab="",
     xaxt="n",
     yaxt="n",
     ylim=c(-2.25,2.25),
     xlim=c(0,1))


abline(a=0,b=0, lwd=1, lty=1)


axis(1,at=seq(0,1,0.1),
     cex.axis=0.8,tck=-0.02)

axis(2,
     at=round(seq(-2.5,2.25,0.5),1),
     cex.axis=0.8,las=2,tck=-0.02)

title(xlab = "standard error (SE)", 
      ylab = "effect size (Zr)",
      line = 2.75, cex.lab=1.4)

points(jitter(xaxis,2),yaxis,
       bg=rgb(0,0,0, 0.1),
       col=rgb(0,0,0, 0.2),
       pch=21,
       cex=1)

lines(newdat$sei, newdat$fit, lwd=2.75,col="darkorchid4") 

polygon(c(newdat$sei,rev(newdat$sei)),
        c(newdat$lower,rev(newdat$upper)),
        border=NA,col=rgb(104/255,34/255,139/255, 0.5))
```

**Figure S2.** Effect sizes with larger SE are larger, which provides evidence of small-study effects in this meta-analytic dataset. The solid line represents the model estimate and shading shows the 95% confidence intervals.

```{r}
# Application of Equation 22 from the main manuscript
publication.bias.model.1.sv <- rma.mv(yi, vi,
                                      mods=~1+vi,
                                      random=list(~ 1 | obsID, ~ 1 | study, ~ 1 | Species.updated),
                                      R = list(Species.updated = phylo_cor), #phylogenetic relatedness
                                      method="REML",data=dataset.r.original)

#summary(publication.bias.model.1.sv)

# extracting the mean and 95% confidence intervals
estimates.publication.bias.model.1.sv <- estimates.CI(publication.bias.model.1.sv)
```

##### **1.3.1.2 - Modelling SV (Eq.22)**

The follow-up meta-regression including the effect sizes' sampling variances (SV or vi) as the only moderator (see Equation 22 from the main text) provides us a less downwardly  biased estimate of the overall effect after accounting for small-study bias. This estimated overall effect corresponds to the intercept of the meta-regression, which corresponds to **`r round(estimates.publication.bias.model.1.sv[1,2],2)` (95% CI = [`r round(estimates.publication.bias.model.1.sv[1,3],2)`,`r round(estimates.publication.bias.model.1.sv[1,4],2)`]**; *R<sup>2</sup><sub>marginal</sub>* = `r round(R2(publication.bias.model.1.sv)[1]*100,1)`%).

<br/><br/>

#### **1.3.2 - Time-lag bias test (Eq.23)**

To test for time-lag bias, also called decline effects, we are again going to fit a multilevel meta-regression that has the same random effect structure as the meta-analytic model (Table S1) and that includes the year of publication as the only moderator (see Equation 23 from the main text). The estimated slope for year will tell us whether effect sizes have become smaller over time since the first effect size was published.

```{r}
# creating a variable with the year of publication
dataset.r.original$year <- as.numeric(str_extract(dataset.r.original$study, "(\\d)+"))

# Application of Equation 23 from the main manuscript
publication.bias.model.1.timelag <- rma.mv(yi, vi,
                                           mods=~1+year,
                                           random=list(~ 1 | obsID, ~ 1 | study, ~ 1 | Species.updated),
                                           R = list(Species.updated = phylo_cor), #phylogenetic relatedness
                                           method="REML",data=dataset.r.original)

#summary(publication.bias.model.1.timelag)

# extracting the mean and 95% confidence intervals
estimates.publication.bias.model.1.timelag <- estimates.CI(publication.bias.model.1.timelag)

```

The time-lag bias test shows no evidence for a decline effect in this dataset (**year slope = `r round(estimates.publication.bias.model.1.timelag[2,2],2)`; 95% CI = [`r round(estimates.publication.bias.model.1.timelag[2,3],2)`,`r round(estimates.publication.bias.model.1.timelag[2,4],2)`]**; *R<sup>2</sup><sub>marginal</sub>* = `r round(R2(publication.bias.model.1.timelag)[1]*100,1)`%; Figure S2).

```{r fig.height = 5.5, fig.width = 7.5, fig.align = "center"}
publication.bias.model.1.timelag.plot <- predict(publication.bias.model.1.timelag,newmods=seq(min(dataset.r.original$year),max(dataset.r.original$year),1))

newdat <- data.frame(year=seq(min(dataset.r.original$year),max(dataset.r.original$year),1),
                     fit=publication.bias.model.1.timelag.plot$pred,
                     upper=publication.bias.model.1.timelag.plot$ci.ub,
                     lower=publication.bias.model.1.timelag.plot$ci.lb,
                     stringsAsFactors=FALSE)


xaxis <- dataset.r.original$year
yaxis <- dataset.r.original$yi
cex.study <- (1/dataset.r.original$sei)/3

plot(xaxis,yaxis,
     type="n",
     ylab="",
     xlab="",
     xaxt="n",
     yaxt="n",
     ylim=c(-2.25,2.25),
     xlim=c(min(xaxis),max(xaxis)))


abline(a=0,b=0, lwd=1, lty=1)


axis(1,at=seq(min(xaxis),max(xaxis),5),
     cex.axis=0.8,tck=-0.02)

axis(2,
     at=round(seq(-2.5,2.25,0.5),1),
     cex.axis=0.8,las=2,tck=-0.02)

title(xlab = "year of publication", 
      ylab = "effect size (Zr)",
      line = 2.75, cex.lab=1.4)

points(jitter(xaxis,2),yaxis,
       bg=rgb(0,0,0, 0.1),
       col=rgb(0,0,0, 0.2),
       pch=21,
       cex=cex.study)

lines(newdat$year, newdat$fit, lwd=2.75,col="darkorchid4") 

polygon(c(newdat$year,rev(newdat$year)),
        c(newdat$lower,rev(newdat$upper)),
        border=NA,col=rgb(104/255,34/255,139/255, 0.5))
```

**Figure S3.** The overall published effect size has remained seemingly unchanged over time since the first effect size was published. The solid line represents the model estimate, shading shows the 95% confidence intervals and individual effect sizes are scaled by their precision (1/SE).

<br/><br/>

#### 1.3.3 - **All-in publication bias test (Eq.24)**

When heterogeneity exists, it is best to combine Equations 21 and 23 with other moderators since those additional moderators will generally explain or be predicted to explain some of the heterogeneity among effect sizes. Therefore, in this case we will run a multilevel meta-regression including the effect sizes' standard errors, the year of publication and the following moderators originally included in Garamszegi et al. (2012): 'taxon class' and 'captivity status' (which accounted for 18.8% of heteregeneity, model not shown).

```{r}
# Application of Equation 24 from the main manuscript
publication.bias.model.1.timelag.all.in <- rma.mv(yi, vi,
                                                  mods=~1+sei+year+Class+CaptivityC,
                                                  random=list(~ 1 | obsID, ~ 1 | study, ~ 1 | Species.updated),
                                                  R = list(Species.updated = phylo_cor), #phylogenetic relatedness
                                                  method="REML",data=dataset.r.original)

summary(publication.bias.model.1.timelag.all.in)
```

**Need to add a little text and probably also a table showing the results of this meta-regresssion, which I did not do because it would be very specific for the dataset we will finally used. Nonetheless, find below the *R<sup>2</sup><sub>marginal</sub>* estimate:**

*R<sup>2</sup><sub>marginal</sub>* = `r round(R2(publication.bias.model.1.timelag.all.in)[1]*100,1)`%

## 2 - Mean differences between two groups

### 2.1 - Meta-analytic model

### 2.2 - Publication bias

#### 2.2.1 - **The two-step approach**

#### 2.2.1.1 - **Sample size quared (Eq.27)**

#### 2.2.1.2 - **Sample size (Eq.28)**

#### 2.2.2 - **Time-lag bias test**

#### 2.2.3 - **All-in publication bias test (Eq.29)**

## R Session Information

```{r}
sessionInfo() %>% pander()
```

## References

To be added.